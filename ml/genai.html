<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Era of GEN AI</title>

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;700&display=swap" rel="stylesheet">

    <!-- Font Awesome Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">

    <!-- MathJax for Equations -->
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>

    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Era of GEN AI</title>

        <!-- Google Fonts -->
        <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;700&display=swap" rel="stylesheet">

        <!-- Font Awesome Icons -->
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">

        <!-- MathJax for Equations -->
        <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

        <style>
            /* Global Styles */
            body {
                font-family: 'Courier New', monospace;
                margin: 0;
                padding: 0;
                color: #ffffff;
                background: url('../assets/images/ml-background.webp') no-repeat center center fixed;
                background-size: cover;
                position: relative;
            }

            /* Dark Overlay */
            body::before {
                content: "";
                position: fixed;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                background: rgba(0, 0, 0, 0.5);
                z-index: -1;
            }

            /* Layout Containers */
            header,
            footer {
                background: linear-gradient(135deg, #0829df, #04013c);
                text-align: center;
                padding: 20px;
                font-size: 24px;
                position: relative;
                z-index: 10;
            }

            main {
                max-width: 900px;
                margin: 40px auto;
                padding: 25px;
                background: rgba(19, 50, 185, 0.85);
                border-radius: 10px;
                box-shadow: 0px 5px 10px rgba(0, 0, 0, 0.2);
                position: relative;
                z-index: 10;
            }

            h1,
            h2,
            h3 {
                color: #d9dcdf;
            }

            /* Styling for Key Sections */
            .case h3 {
                color: #ffcc00;
            }

            .case p {
                color: #ffffff;
            }

            /* Table Styles */
            table {
                font-family: 'Courier New', monospace;
                width: 100%;
                border-collapse: collapse;
                margin: 10px 0;
                background: rgba(255, 255, 255, 0.1);
            }

            th,
            td {
                border: 1px solid #ccc;
                padding: 8px;
                text-align: center;
                font-size: 14px;
            }

            th {
                background: rgba(0, 0, 0, 0.2);
            }

            /* Image Styling */
            .image-container {
                text-align: center;
                margin: 10px 0;
            }

            .image-container img {
                width: 35%;
                border-radius: 5px;
                box-shadow: 0px 5px 10px rgba(0, 0, 0, 0.2);
            }

            /* Content Alignment */
            .content-container {
                display: flex;
                align-items: center;
                justify-content: space-between;
                gap: 10px;
            }

            .image-container {
                flex: 1;
            }

            .image-container img {
                width: 65%;
                border-radius: 10px;
            }

            .text-container {
                flex: 1;
                width: 55%;
            }

            /* Failure Cases Section */
            .failure-cases {
                width: 90%;
                max-width: 1600px;
                background: rgba(255, 255, 255, 0.1);
                padding: 20px;
                border-radius: 8px;
                box-shadow: 0px 5px 10px rgba(0, 0, 0, 0.2);
                margin: 20px auto;
                text-align: justify;
            }

            .case {
                width: 100%;
                background: rgba(255, 255, 255, 0.15);
                padding: 15px;
                margin-bottom: 15px;
                border-radius: 6px;
            }

            /* Decision Tree Node Styles */
            .node circle {
                fill: #69b3a2;
                stroke: #555;
                stroke-width: 2px;
            }

            .node text {
                font-size: 14px;
                font-family: 'Courier New', monospace;
                fill: white;
            }

            .link {
                fill: none;
                stroke: #ccc;
                stroke-width: 2px;
            }

            a {
                color: #ffcc00;
                text-decoration: underline;
                font-weight: bold;
            }

            a:hover {
                color: #ffffff;
                text-decoration: none;
            }

            .floating-sidebar {
                position: fixed;
                top: 50%;
                left: -120px;
                /* Partially hidden */
                width: 150px;
                /* Explicit width */
                transform: translateY(-50%);
                background-color: rgba(143, 137, 137, 0.5);
                padding: 15px;
                border-radius: 0 10px 10px 0;
                box-shadow: 2px 2px 10px rgb(255, 255, 255);
                transition: left 0.3s ease;
                /* Smooth slide */
            }

            /* Reveal sidebar on hover */
            .floating-sidebar:hover {
                left: 0;
                /* Fully visible */
            }

            /* Sidebar Link */
            .floating-sidebar a {
                color: white;
                text-decoration: none;
                font-size: 18px;
                font-family: Arial, sans-serif;
                display: block;
                padding: 10px 0;
                transition: color 0.3s ease;
            }

            /* Hover effect for links */
            .floating-sidebar a:hover {
                color: #FFD700;
                /* Golden color on hover */
            }
        </style>

    </head>

    <header>
        <h1>Generative AI </h1>
    </header>

<body>
    <div class="failure-cases">
        <div class="case" style="font-family: 'Courier New', monospace; padding: 10px; border: 1px solid #ddd;">
            <!DOCTYPE html>
            <html lang="en">

            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <title>Building Generative AI from Scratch</title>
            </head>

            <body>
                <h1>Building Generative AI from Scratch: A Technical Deep Dive</h1>

                <p>Generative AI (GenAI) has revolutionized various industries, from creative content generation to
                    advanced data augmentation. But how exactly was Generative AI built from scratch? In this blog, we
                    will explore the fundamental building blocks of GenAI, tracing its evolution from basic neural
                    networks to state-of-the-art transformer architectures.</p>

                <h2>1. Foundations of Generative AI</h2>
                <p>Before deep diving into the technical aspects, let's outline the foundational concepts required to
                    build Generative AI:</p>
                <ul>
                    <li><b>Neural Networks:</b> The fundamental units of deep learning, consisting of layers of neurons
                        trained on data.</li>
                    <li><b>Probability and Statistics:</b> Essential for understanding likelihood estimation in
                        generative models.</li>
                    <li><b>Optimization Algorithms:</b> Techniques like Stochastic Gradient Descent (SGD) and Adam used
                        to train models.</li>
                    <li><b>Backpropagation:</b> The core algorithm for updating neural network weights based on
                        gradients.</li>
                </ul>

                <h2>2. How ChatGPT Was Trained</h2>
                <p>ChatGPT, one of the most widely used generative AI models, was trained using a multi-stage process
                    that involved large-scale datasets, self-supervised learning, and reinforcement learning with human
                    feedback. The training process can be broken down into the following steps:</p>

                <h3>a. Pretraining on Large Text Corpora</h3>
                <p>The model was trained on a diverse dataset containing books, articles, websites, and other publicly
                    available text sources. Using a process called <b><a href="../ml/causallanguagemodeling.html"
                            target="_blank" rel="noopener noreferrer"
                            aria-label="Learn more about causal language modeling"
                            style="color: #20a359; font-weight: italic;">
                            causal language modeling,</a></b> the model learned to
                    predict the next word in a sentence, enabling it to generate coherent text.</p>

                <h3>b. <a href="../ml/finetuning.html" target="_blank" rel="noopener noreferrer"
                        aria-label="Learn more about Supervised Fine-Tuning"
                        style="color: #20a359; font-weight: italic;">
                        Supervised Fine-Tuning</a></h3>
                <p>Once pretraining was completed, the model was fine-tuned using human-annotated datasets. This step
                    helped refine its ability to generate accurate and contextually relevant responses.</p>

                <h3>c. Reinforcement Learning from Human Feedback (RLHF)</h3>
                <p>To further improve response quality, OpenAI employed Reinforcement Learning from Human Feedback
                    (RLHF). This process involved:</p>
                <ul>
                    <li><b>Human Labeling:</b> Human annotators ranked multiple responses from the model.</li>
                    <li><b>Reward Model:</b> A secondary model learned from human preferences to rate responses.</li>
                    <li><b>Optimization:</b> Using Proximal Policy Optimization (PPO), the model was fine-tuned to
                        prioritize higher-rated responses.</li>
                </ul>

                <h3>d. Sample Text Training Through All Stages</h3>
                <p>Let’s take an example text and walk through how it would be processed at each stage of training:</p>

                <h4>1. Pretraining Stage:</h4>
                <pre>
                    Raw text: "Transformers have changed AI by introducing self-attention mechanisms."
                    
                    Model learns patterns by predicting the next word:
                    Input: "Transformers have"
                    Output: "changed"
                </pre>
                <p>The model is trained on massive amounts of text using this process, gradually improving its ability
                    to generate fluent and contextually relevant sentences.</p>

                <h4>2. Supervised Fine-Tuning Stage:</h4>
                <pre>
                    Annotators provide a more detailed and structured response:
                    Input: "Explain transformers in AI."
                    Target Output: "Transformers are deep learning models that use self-attention to process entire sequences efficiently."
                </pre>
                <p>The model is then adjusted to generate more human-like and informative responses.</p>

                <h4>3. Reinforcement Learning from Human Feedback (RLHF) Stage:</h4>
                <pre>
                    Multiple model responses are generated and ranked by human reviewers:
                    
                    Response 1: "Transformers are great for AI."
                    Response 2: "Transformers revolutionized AI by enabling parallel processing of sequences."
                    Response 3: "Transformers use self-attention to improve deep learning architectures."
                    
                    Ranking by human annotators:
                    - Best: Response 2
                    - Worst: Response 1
                </pre>
                <p>The reward model learns from these rankings and optimizes the system to produce more useful
                    responses.</p>

                <h2>3. Future Developments</h2>
                <p>With ongoing research, future iterations of ChatGPT and other generative AI models aim to improve
                    efficiency, reduce biases, and enhance their ability to generate human-like responses. Techniques
                    such as model distillation and smaller, efficient architectures will help make generative AI more
                    accessible.</p>
            </body>

            </html>
        </div>
    </div>
    <!-- Floating Sidebar -->
    <div class="floating-sidebar">
        <a href="../ml/finetunellm.html">LLM Fine Tuning</a>
        <!-- <a href="../ml/causallanguagemodeling.html">Causal Language Modeling</a>
        <a href="../ml/finetuning.html">SuperVised Fine Tuning</a> -->
    </div>
    <div class="failure-cases">
        <div class="case" style="font-family: 'Courier New', monospace; padding: 10px; border: 1px solid #ddd;">
            <div class="prompt-engineering">
                <h2>Prompt Engineering Techniques</h2>
                <h3>1. Zero-Shot Prompting:</h3>
                <p><strong>What it is:</strong> Directly asking the model to perform a task without any examples.
                </p>
                <p><strong>Example:</strong> “Summarize the following text: [text]”</p>
                <p><strong>Use case:</strong> Quick tasks where the model leverages general pretraining.</p>

                <h3>2. One-Shot Prompting:</h3>
                <p><strong>What it is:</strong> Providing one example in the prompt to guide the model.</p>
                <p><strong>Example:</strong> “Translate the following sentence to French. Example: ‘Hello’ →
                    ‘Bonjour’.
                    Now translate: ‘Goodbye’”</p>
                <p><strong>Use case:</strong> When minimal context is enough to improve performance.</p>

                <h3>3. Few-Shot Prompting:</h3>
                <p><strong>What it is:</strong> Including multiple examples to help the model understand the task
                    better.</p>
                <p><strong>Example:</strong></p>
                <pre>
          Classify the sentiment:
          - ‘I love this product!’ → Positive
          - ‘This is terrible.’ → Negative
          - ‘It’s okay, not great.’ → Neutral
          Now classify: ‘Absolutely amazing!’
                </pre>
                <p><strong>Use case:</strong> Complex tasks where multiple examples improve accuracy.</p>

                <h3>4. Chain-of-Thought Prompting:</h3>
                <p><strong>What it is:</strong> Encouraging the model to explain its reasoning step-by-step.</p>
                <p><strong>Example:</strong> “If there are 5 apples and you eat 2, how many are left? Let’s think
                    step
                    by step.”</p>
                <p><strong>Use case:</strong> Tasks requiring logical reasoning or multi-step solutions.</p>

                <h3>5. Instruction Tuning:</h3>
                <p><strong>What it is:</strong> Fine-tuning LLMs on instruction-based datasets to follow commands
                    better.</p>
                <p><strong>Example:</strong> Models like <strong>InstructGPT</strong> or <strong>ChatGPT</strong>.
                </p>
                <p><strong>Use case:</strong> Enhancing model adherence to user instructions.</p>
            </div>
        </div>
    </div>
    </div>
    <div class="failure-cases">
        <div class="case" style="font-family: 'Courier New', monospace; padding: 10px; border: 1px solid #ddd;">
            <div class="fine-tuning-techniques">
                <h2>Parameter-Efficient Fine-Tuning Techniques</h2>

                <h3>1. LoRA (Low-Rank Adaptation):</h3>
                <p><strong>What it is:</strong> A method that injects trainable low-rank matrices into each layer of the
                    pretrained model, reducing the number of trainable parameters.</p>
                <p><strong>Key Benefits:</strong></p>
                <ul>
                    <li>Requires less memory and computation.</li>
                    <li>Fine-tunes only the injected matrices while keeping the base model frozen.</li>
                </ul>
                <p><strong>Use case:</strong> Ideal for resource-constrained fine-tuning without sacrificing
                    performance.</p>

                <h3>2. Adapters:</h3>
                <p><strong>What it is:</strong> Small trainable neural network modules inserted between the layers of a
                    frozen pretrained model.</p>
                <p><strong>Key Benefits:</strong></p>
                <ul>
                    <li>Only adapters are trained, keeping the original model intact.</li>
                    <li>Allows for easy switching between different tasks/domains by swapping adapters.</li>
                </ul>
                <p><strong>Use case:</strong> Multi-task learning and domain adaptation with minimal overhead.</p>

                <h3>3. P-Tuning (Prompt Tuning):</h3>
                <p><strong>What it is:</strong> Introduces continuous, trainable prompt embeddings into the model input,
                    guiding the LLM’s behavior without modifying core parameters.</p>
                <p><strong>Key Benefits:</strong></p>
                <ul>
                    <li>Extremely lightweight—only the prompt embeddings are trained.</li>
                    <li>Effective for specific downstream tasks with fewer resources.</li>
                </ul>
                <p><strong>Use case:</strong> Task-specific fine-tuning (e.g., classification, QA) with minimal cost.
                </p>
            </div>

        </div>
    </div>
    <div class="failure-cases">
        <div class="case" style="font-family: 'Courier New', monospace; padding: 10px; border: 1px solid #ddd;">
            <div class="training-optimization-challenges">
                <h2>Training & Optimization Challenges</h2>

                <h3>1. Training Stability:</h3>
                <p>Ensuring stability during model training is crucial to avoid issues like divergence and sub-optimal
                    convergence.</p>

                <h4>GAN Mode Collapse:</h4>
                <p><strong>What it is:</strong> A common issue in Generative Adversarial Networks (GANs) where the
                    generator produces a limited variety of outputs, leading to low diversity.</p>
                <p><strong>Solutions:</strong></p>
                <ul>
                    <li>Use Wasserstein GAN (WGAN) for better training stability.</li>
                    <li>Implement techniques like feature matching or mini-batch discrimination.</li>
                </ul>

                <h4>VAE Posterior Collapse:</h4>
                <p><strong>What it is:</strong> In Variational Autoencoders (VAEs), the decoder may ignore the latent
                    space, leading to a collapsed posterior where the latent variables carry minimal information.</p>
                <p><strong>Solutions:</strong></p>
                <ul>
                    <li>Apply KL annealing to gradually introduce regularization.</li>
                    <li>Use β-VAE to balance the trade-off between reconstruction and latent space learning.</li>
                </ul>

                <h4>Gradient Clipping:</h4>
                <p><strong>What it is:</strong> A technique to prevent exploding gradients by capping the gradients
                    during backpropagation.</p>
                <p><strong>Benefit:</strong> Helps stabilize training, especially in recurrent or deep networks.</p>

                <h4>Learning Rate Schedules:</h4>
                <p><strong>What it is:</strong> Dynamically adjusting the learning rate during training to balance
                    convergence speed and stability.</p>
                <p><strong>Common Strategies:</strong></p>
                <ul>
                    <li><strong>Step Decay:</strong> Reduce learning rate by a factor after certain epochs.</li>
                    <li><strong>Cosine Annealing:</strong> Smoothly decay the learning rate following a cosine curve.
                    </li>
                    <li><strong>Warm-up:</strong> Gradually increase the learning rate at the beginning of training.
                    </li>
                </ul>

                <h3>2. Scalability:</h3>
                <p>Training large-scale models requires strategies to efficiently scale computation across hardware and
                    manage memory.</p>

                <h4>Data Parallelism:</h4>
                <p><strong>What it is:</strong> Splitting data across multiple GPUs or nodes, with each processing a
                    portion of the dataset.</p>
                <p><strong>Benefit:</strong> Enables faster training by leveraging multiple devices.</p>

                <h4>Model Parallelism:</h4>
                <p><strong>What it is:</strong> Distributing different parts of a large model across multiple devices.
                </p>
                <p><strong>Benefit:</strong> Allows training models too large to fit in a single device’s memory.</p>

                <h4>Memory Optimization Strategies:</h4>
                <ul>
                    <li><strong>Gradient Checkpointing:</strong> Saves memory by selectively storing activations and
                        recomputing them during backpropagation.</li>
                    <li><strong>Mixed Precision Training:</strong> Uses lower-precision (e.g., FP16) computations to
                        reduce memory usage and speed up training.</li>
                    <li><strong>Offloading:</strong> Moves certain computations (e.g., optimizer states) to CPU or
                        secondary memory to reduce GPU load.</li>
                </ul>
            </div>

        </div>
    </div>
    <div class="failure-cases">
        <div class="case" style="font-family: 'Courier New', monospace; padding: 10px; border: 1px solid #ddd;">
            <div class="evaluation-metrics">
                <h2>5. Evaluation Metrics</h2>

                <h3>Text Generation:</h3>
                <p>Evaluating text generation models involves metrics that assess both fluency and relevance of the
                    generated content.</p>
                <ul>
                    <li><strong>Perplexity:</strong> Measures how well a probabilistic model predicts a sample. Lower
                        perplexity indicates better performance.</li>
                    <li><strong>BLEU (Bilingual Evaluation Understudy):</strong> Evaluates n-gram overlaps between
                        generated and reference texts, commonly used in machine translation.</li>
                    <li><strong>ROUGE (Recall-Oriented Understudy for Gisting Evaluation):</strong> Focuses on recall,
                        measuring overlapping units like n-grams and word sequences, often used in summarization tasks.
                    </li>
                    <li><strong>METEOR (Metric for Evaluation of Translation with Explicit ORdering):</strong> Considers
                        exact word matches, stemmed matches, and synonyms, improving over BLEU for nuanced text
                        generation.</li>
                    <li><strong>BERTScore:</strong> Uses contextual embeddings from BERT to compute similarity between
                        generated and reference texts, capturing semantic relevance.</li>
                </ul>

                <h3>Image Generation:</h3>
                <p>Image generation models are evaluated based on realism and diversity of generated images.</p>
                <ul>
                    <li><strong>Inception Score (IS):</strong> Assesses image quality and diversity by analyzing
                        features from an Inception model. Higher scores indicate better quality and diversity.</li>
                    <li><strong>Frechet Inception Distance (FID):</strong> Compares the distribution of generated images
                        to real images using feature embeddings. Lower FID indicates more realistic and diverse images.
                    </li>
                </ul>

                <h3>Ethical Considerations:</h3>
                <p>Evaluating generative models goes beyond accuracy, focusing on fairness, safety, and ethical use.</p>
                <ul>
                    <li><strong>Bias in Generative Models:</strong> Generative models can inadvertently reinforce
                        harmful stereotypes or exhibit biases present in training data. Evaluating and mitigating these
                        biases is critical.</li>
                    <li><strong>Responsible AI and Hallucination in LLMs:</strong> Large Language Models (LLMs) can
                        generate plausible but factually incorrect or harmful content ("hallucinations"). Responsible AI
                        practices involve monitoring and controlling such outputs.</li>
                </ul>
            </div>

        </div>
    </div>
    <div class="failure-cases">
        <div class="case" style="font-family: 'Courier New', monospace; padding: 10px; border: 1px solid #ddd;">
            <div class="rag-blog">
                <h1>Retrieval-Augmented Generation (RAG):</h1>
                <p><strong>RAG <a href="../ml/rag.html" target="_blank" rel="noopener noreferrer"
                            aria-label="Learn more about RAG" style="color: #20a359; font-weight: italic;">
                            (Retrieval-Augmented Generation)</a></strong> is a technique that combines
                    <strong>retrieval</strong> and <strong>generation</strong>
                    to improve the performance of language models. Instead of relying solely on pre-trained knowledge,
                    RAG retrieves relevant documents or context from an external knowledge base (like a vector store or
                    search
                    engine) and feeds this information into a generative model (like GPT) to produce more accurate,
                    grounded, and up-to-date responses.
                </p>

                <p>💡 <strong>Key Benefit:</strong> It bridges the gap between static knowledge in LLMs and dynamic,
                    external
                    information, reducing hallucinations and improving factual accuracy. 🚀📚</p>
            </div>



        </div>
    </div>
</body>

</html>